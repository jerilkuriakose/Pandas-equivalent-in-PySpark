# Pandas-equivalent-in-PySpark
**pandas** is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language. *pandas* allows us to focus more on research and less on programming. *pandas* is the perfect tool for bridging the gap between rapid iterations of ad-hoc analysis and production quality code [[Source](http://pandas.pydata.org/)].

**Apache Spark** is a fast and general engine for large-scale data processing. Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster on disk. Spark runs on Hadoop, Mesos, standalone, or in the cloud. It can access diverse data sources including HDFS, Cassandra, HBase, and S3 [[Source](https://spark.apache.org/)].

This repo has the PySpark equivalent code for the *pandas* queries. This can save a lot of time in Googling.

## Dependencies
1. Python 3.5.2
2. Spark 2.2.0
3. PySpark 2.2.0
4. Pandas 0.21.0

## Table of contents
1. [Chapter 1 - File handling](http://nbviewer.jupyter.org/github/jerilkuriakose/Pandas-equivalent-in-PySpark/blob/master/notebooks/Chapter%201%20-%20CSV%20file%20handling.ipynb)

## Contributing to the repo
All contributions, bug reports, bug fixes, documentation improvements, enhancements and ideas are welcome.

A detailed overview on how to contribute can be found in the **[contributing guide.](https://pandas.pydata.org/pandas-docs/stable/contributing.html)**

If you are simply looking to start working with the repo's codebase, navigate to the [GitHub “issues” tab](https://github.com/jerilkuriakose/Pandas-equivalent-in-PySpark/issues) and start looking through interesting issues.

[Code of Conduct](https://github.com/jerilkuriakose/Pandas-equivalent-in-PySpark/blob/master/CODE_OF_CONDUCT.md)
